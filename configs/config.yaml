#config.yaml
defaults:
  - model: unetDoubleAttention
  - train: default
  - optimizer: adam
  - scheduler: plateau
  - logger: mlflow
  # - override hydra/sweeper: optuna  #Uncomment for optimization
  - _self_

seed: 654321
mode: final  #Change to optimize from final for hyperparameter sweep

#Uncomment for Optuna sweeper
# hydra:
#   sweeper:
#     _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
#     direction: maximize
#     storage: null
#     study_name: UnetAttention_Gaussian_0.15
#     n_trials: 45
#     n_jobs: 1
#     sampler:
#       _target_: optuna.samplers.TPESampler
#       seed: 654321
#       consider_prior: true
#       prior_weight: 1.0
#       consider_magic_clip: true
#       consider_endpoints: false
#       n_startup_trials: 10
#       n_ei_candidates: 24
#       multivariate: false
#       warn_independent_sampling: true
#     params:
#       optimizer.lr: range(0.0001, 0.001, step=0.0001)
#       optimizer.weight_decay: range(0.0, 0.0001, step=0.00001)
#       train.batch_size: choice(64, 128)
#       train.epochs: choice(5, 10)
#       scheduler.factor: range(0.1, 0.5, step=0.1)
#       scheduler.patience: choice(3,5,7)
#       scheduler.min_lr: range(0.00001, 0.0001, step=0.00001)
#       scheduler.eps: range(1e-08, 1e-07, step=1e-08)
#       model.sumOrElement: choice(true, false)
#   run:
#     dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

#comment this out for optuna sweep
hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
